
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Tugas 7 - Diabetic Retinopathy &#8212; Saiyidati Vienna Arum Pratama</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Tugas 8 - Regression Linier" href="Tugas%208.html" />
    <link rel="prev" title="Tugas 6 - Decision Tree" href="Tugas%206.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/vienna.jpg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Saiyidati Vienna Arum Pratama</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Data Mining
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Penambangan Data
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Tugas%201.html">
   Tugas 1 - Statistika Deskriptif
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Tugas%202.html">
   Tugas 2 - Diskritisasi
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Tugas%203.html">
   Tugas 3 - K-Nearest Neighbor
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Tugas%204.html">
   Tugas 4 - Gaussian Naive Bayes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="UTS.html">
   UTS Penambangan Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Tugas%205.html">
   Tugas 5 - K-Means Clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Tugas%206.html">
   Tugas 6 - Decision Tree
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Tugas 7 - Diabetic Retinopathy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Tugas%208.html">
   Tugas 8 - Regression Linier
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://colab.research.google.com/github/saiyidativiennaarumpratama/datamining/blob/gh-pages/_sources/Tugas 7.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/saiyidativiennaarumpratama/datamining"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/saiyidativiennaarumpratama/datamining/issues/new?title=Issue%20on%20page%20%2FTugas 7.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/Tugas 7.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Tugas 7 - Diabetic Retinopathy
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#preprocessing">
   <strong>
    Preprocessing
   </strong>
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#normalisasi-min-max">
     Normalisasi Min - Max
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#modelling">
   <strong>
    Modelling
   </strong>
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bagging-classifier">
   <strong>
    Bagging Classifier
   </strong>
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Tugas 7 - Diabetic Retinopathy</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Tugas 7 - Diabetic Retinopathy
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#preprocessing">
   <strong>
    Preprocessing
   </strong>
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#normalisasi-min-max">
     Normalisasi Min - Max
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#modelling">
   <strong>
    Modelling
   </strong>
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bagging-classifier">
   <strong>
    Bagging Classifier
   </strong>
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="tugas-7-diabetic-retinopathy">
<h1>Tugas 7 - Diabetic Retinopathy<a class="headerlink" href="#tugas-7-diabetic-retinopathy" title="Permalink to this headline">#</a></h1>
<p>Nama : Saiyidati Vienna Arum Pratama<br />
Nim  : 200411100018<br />
Kelas: Penambangan Data IF 5A</p>
<p>Dataset : Dataset messidor_features</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.io</span> <span class="kn">import</span> <span class="n">arff</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># one hot enconder</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>

<span class="c1"># min max scaler to normalize</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>

<span class="c1"># library for Naive Bayes Gaussian</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">make_scorer</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span><span class="n">precision_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_score</span><span class="p">,</span><span class="n">recall_score</span><span class="p">,</span><span class="n">f1_score</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>

<span class="c1">#Model Select</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">col_names</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">col_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;quality&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">col_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;prescreen&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="mi">7</span><span class="p">:</span>
        <span class="n">col_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;ma&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="mi">8</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="mi">15</span><span class="p">:</span>
        <span class="n">col_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;exudate&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">16</span><span class="p">:</span>
        <span class="n">col_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;euDist&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">17</span><span class="p">:</span>
        <span class="n">col_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;diameter&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">18</span><span class="p">:</span>
        <span class="n">col_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;amfm_class&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">19</span><span class="p">:</span>
        <span class="n">col_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;label&#39;</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">arff</span><span class="o">.</span><span class="n">loadarff</span><span class="p">(</span><span class="s1">&#39;/content/drive/MyDrive/datamining/tugas/messidor_features.arff&#39;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">col_names</span><span class="p">]</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-187e354a-90d4-497c-bb90-24a0ddb99c87">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>quality</th>
      <th>prescreen</th>
      <th>ma2</th>
      <th>ma3</th>
      <th>ma4</th>
      <th>ma5</th>
      <th>ma6</th>
      <th>ma7</th>
      <th>exudate8</th>
      <th>exudate9</th>
      <th>exudate10</th>
      <th>exudate11</th>
      <th>exudate12</th>
      <th>exudate13</th>
      <th>exudate14</th>
      <th>exudate15</th>
      <th>euDist</th>
      <th>diameter</th>
      <th>amfm_class</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>22.0</td>
      <td>22.0</td>
      <td>22.0</td>
      <td>19.0</td>
      <td>18.0</td>
      <td>14.0</td>
      <td>49.895756</td>
      <td>17.775994</td>
      <td>5.270920</td>
      <td>0.771761</td>
      <td>0.018632</td>
      <td>0.006864</td>
      <td>0.003923</td>
      <td>0.003923</td>
      <td>0.486903</td>
      <td>0.100025</td>
      <td>1.0</td>
      <td>b'0'</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>24.0</td>
      <td>24.0</td>
      <td>22.0</td>
      <td>18.0</td>
      <td>16.0</td>
      <td>13.0</td>
      <td>57.709936</td>
      <td>23.799994</td>
      <td>3.325423</td>
      <td>0.234185</td>
      <td>0.003903</td>
      <td>0.003903</td>
      <td>0.003903</td>
      <td>0.003903</td>
      <td>0.520908</td>
      <td>0.144414</td>
      <td>0.0</td>
      <td>b'0'</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>62.0</td>
      <td>60.0</td>
      <td>59.0</td>
      <td>54.0</td>
      <td>47.0</td>
      <td>33.0</td>
      <td>55.831441</td>
      <td>27.993933</td>
      <td>12.687485</td>
      <td>4.852282</td>
      <td>1.393889</td>
      <td>0.373252</td>
      <td>0.041817</td>
      <td>0.007744</td>
      <td>0.530904</td>
      <td>0.128548</td>
      <td>0.0</td>
      <td>b'1'</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>55.0</td>
      <td>53.0</td>
      <td>53.0</td>
      <td>50.0</td>
      <td>43.0</td>
      <td>31.0</td>
      <td>40.467228</td>
      <td>18.445954</td>
      <td>9.118901</td>
      <td>3.079428</td>
      <td>0.840261</td>
      <td>0.272434</td>
      <td>0.007653</td>
      <td>0.001531</td>
      <td>0.483284</td>
      <td>0.114790</td>
      <td>0.0</td>
      <td>b'0'</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>44.0</td>
      <td>44.0</td>
      <td>44.0</td>
      <td>41.0</td>
      <td>39.0</td>
      <td>27.0</td>
      <td>18.026254</td>
      <td>8.570709</td>
      <td>0.410381</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.475935</td>
      <td>0.123572</td>
      <td>0.0</td>
      <td>b'1'</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1146</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>34.0</td>
      <td>34.0</td>
      <td>34.0</td>
      <td>33.0</td>
      <td>31.0</td>
      <td>24.0</td>
      <td>6.071765</td>
      <td>0.937472</td>
      <td>0.031145</td>
      <td>0.003115</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.537470</td>
      <td>0.116795</td>
      <td>0.0</td>
      <td>b'0'</td>
    </tr>
    <tr>
      <th>1147</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>49.0</td>
      <td>49.0</td>
      <td>49.0</td>
      <td>49.0</td>
      <td>45.0</td>
      <td>37.0</td>
      <td>63.197145</td>
      <td>27.377668</td>
      <td>8.067688</td>
      <td>0.979548</td>
      <td>0.001552</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.516733</td>
      <td>0.124190</td>
      <td>0.0</td>
      <td>b'0'</td>
    </tr>
    <tr>
      <th>1148</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>49.0</td>
      <td>48.0</td>
      <td>48.0</td>
      <td>45.0</td>
      <td>43.0</td>
      <td>33.0</td>
      <td>30.461898</td>
      <td>13.966980</td>
      <td>1.763305</td>
      <td>0.137858</td>
      <td>0.011221</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.560632</td>
      <td>0.129843</td>
      <td>0.0</td>
      <td>b'0'</td>
    </tr>
    <tr>
      <th>1149</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>39.0</td>
      <td>36.0</td>
      <td>29.0</td>
      <td>23.0</td>
      <td>13.0</td>
      <td>7.0</td>
      <td>40.525739</td>
      <td>12.604947</td>
      <td>4.740919</td>
      <td>1.077570</td>
      <td>0.563518</td>
      <td>0.326860</td>
      <td>0.239568</td>
      <td>0.174584</td>
      <td>0.485972</td>
      <td>0.106690</td>
      <td>1.0</td>
      <td>b'1'</td>
    </tr>
    <tr>
      <th>1150</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>7.0</td>
      <td>7.0</td>
      <td>7.0</td>
      <td>7.0</td>
      <td>7.0</td>
      <td>5.0</td>
      <td>69.423565</td>
      <td>7.031843</td>
      <td>1.750548</td>
      <td>0.046597</td>
      <td>0.021180</td>
      <td>0.008472</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.556192</td>
      <td>0.088957</td>
      <td>0.0</td>
      <td>b'0'</td>
    </tr>
  </tbody>
</table>
<p>1151 rows × 20 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-187e354a-90d4-497c-bb90-24a0ddb99c87')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-187e354a-90d4-497c-bb90-24a0ddb99c87 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-187e354a-90d4-497c-bb90-24a0ddb99c87');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">X</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py:4150: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.
  obj = obj._drop_axis(labels, axis, level=level, errors=errors)
</pre></div>
</div>
<div class="output text_html">
  <div id="df-baf3d2d5-f49b-466b-8268-a583eb6120e3">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>quality</th>
      <th>prescreen</th>
      <th>ma2</th>
      <th>ma3</th>
      <th>ma4</th>
      <th>ma5</th>
      <th>ma6</th>
      <th>ma7</th>
      <th>exudate8</th>
      <th>exudate9</th>
      <th>exudate10</th>
      <th>exudate11</th>
      <th>exudate12</th>
      <th>exudate13</th>
      <th>exudate14</th>
      <th>exudate15</th>
      <th>euDist</th>
      <th>diameter</th>
      <th>amfm_class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>22.0</td>
      <td>22.0</td>
      <td>22.0</td>
      <td>19.0</td>
      <td>18.0</td>
      <td>14.0</td>
      <td>49.895756</td>
      <td>17.775994</td>
      <td>5.270920</td>
      <td>0.771761</td>
      <td>0.018632</td>
      <td>0.006864</td>
      <td>0.003923</td>
      <td>0.003923</td>
      <td>0.486903</td>
      <td>0.100025</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>24.0</td>
      <td>24.0</td>
      <td>22.0</td>
      <td>18.0</td>
      <td>16.0</td>
      <td>13.0</td>
      <td>57.709936</td>
      <td>23.799994</td>
      <td>3.325423</td>
      <td>0.234185</td>
      <td>0.003903</td>
      <td>0.003903</td>
      <td>0.003903</td>
      <td>0.003903</td>
      <td>0.520908</td>
      <td>0.144414</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>62.0</td>
      <td>60.0</td>
      <td>59.0</td>
      <td>54.0</td>
      <td>47.0</td>
      <td>33.0</td>
      <td>55.831441</td>
      <td>27.993933</td>
      <td>12.687485</td>
      <td>4.852282</td>
      <td>1.393889</td>
      <td>0.373252</td>
      <td>0.041817</td>
      <td>0.007744</td>
      <td>0.530904</td>
      <td>0.128548</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>55.0</td>
      <td>53.0</td>
      <td>53.0</td>
      <td>50.0</td>
      <td>43.0</td>
      <td>31.0</td>
      <td>40.467228</td>
      <td>18.445954</td>
      <td>9.118901</td>
      <td>3.079428</td>
      <td>0.840261</td>
      <td>0.272434</td>
      <td>0.007653</td>
      <td>0.001531</td>
      <td>0.483284</td>
      <td>0.114790</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>44.0</td>
      <td>44.0</td>
      <td>44.0</td>
      <td>41.0</td>
      <td>39.0</td>
      <td>27.0</td>
      <td>18.026254</td>
      <td>8.570709</td>
      <td>0.410381</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.475935</td>
      <td>0.123572</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1146</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>34.0</td>
      <td>34.0</td>
      <td>34.0</td>
      <td>33.0</td>
      <td>31.0</td>
      <td>24.0</td>
      <td>6.071765</td>
      <td>0.937472</td>
      <td>0.031145</td>
      <td>0.003115</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.537470</td>
      <td>0.116795</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1147</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>49.0</td>
      <td>49.0</td>
      <td>49.0</td>
      <td>49.0</td>
      <td>45.0</td>
      <td>37.0</td>
      <td>63.197145</td>
      <td>27.377668</td>
      <td>8.067688</td>
      <td>0.979548</td>
      <td>0.001552</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.516733</td>
      <td>0.124190</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1148</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>49.0</td>
      <td>48.0</td>
      <td>48.0</td>
      <td>45.0</td>
      <td>43.0</td>
      <td>33.0</td>
      <td>30.461898</td>
      <td>13.966980</td>
      <td>1.763305</td>
      <td>0.137858</td>
      <td>0.011221</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.560632</td>
      <td>0.129843</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1149</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>39.0</td>
      <td>36.0</td>
      <td>29.0</td>
      <td>23.0</td>
      <td>13.0</td>
      <td>7.0</td>
      <td>40.525739</td>
      <td>12.604947</td>
      <td>4.740919</td>
      <td>1.077570</td>
      <td>0.563518</td>
      <td>0.326860</td>
      <td>0.239568</td>
      <td>0.174584</td>
      <td>0.485972</td>
      <td>0.106690</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1150</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>7.0</td>
      <td>7.0</td>
      <td>7.0</td>
      <td>7.0</td>
      <td>7.0</td>
      <td>5.0</td>
      <td>69.423565</td>
      <td>7.031843</td>
      <td>1.750548</td>
      <td>0.046597</td>
      <td>0.021180</td>
      <td>0.008472</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.556192</td>
      <td>0.088957</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>1151 rows × 19 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-baf3d2d5-f49b-466b-8268-a583eb6120e3')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-baf3d2d5-f49b-466b-8268-a583eb6120e3 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-baf3d2d5-f49b-466b-8268-a583eb6120e3');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="preprocessing">
<h1><strong>Preprocessing</strong><a class="headerlink" href="#preprocessing" title="Permalink to this headline">#</a></h1>
<section id="normalisasi-min-max">
<h2>Normalisasi Min - Max<a class="headerlink" href="#normalisasi-min-max" title="Permalink to this headline">#</a></h2>
<div class="math notranslate nohighlight">
\[ x'=\frac{x-x_{min}}{x_{max}-x_{min}}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>

<span class="kn">import</span> <span class="nn">joblib</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="c1">#scaler.transform(features)</span>
<span class="n">scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="c1">#memasukan fitur </span>
<span class="n">features_names</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="c1">#features_names.remove(&#39;label&#39;)</span>
<span class="n">scaled_features</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scaled</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">features_names</span><span class="p">)</span>
<span class="n">scaled_features</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">scaler_filename</span> <span class="o">=</span> <span class="s2">&quot;scaled.save&quot;</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">scaler</span><span class="p">,</span> <span class="n">scaler_filename</span><span class="p">)</span> 
<span class="n">scaler</span> <span class="o">=</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">scaler_filename</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scaled_features</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-608d881d-90b8-4a40-bee5-01538deb003c">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>quality</th>
      <th>prescreen</th>
      <th>ma2</th>
      <th>ma3</th>
      <th>ma4</th>
      <th>ma5</th>
      <th>ma6</th>
      <th>ma7</th>
      <th>exudate8</th>
      <th>exudate9</th>
      <th>exudate10</th>
      <th>exudate11</th>
      <th>exudate12</th>
      <th>exudate13</th>
      <th>exudate14</th>
      <th>exudate15</th>
      <th>euDist</th>
      <th>diameter</th>
      <th>amfm_class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.140000</td>
      <td>0.160305</td>
      <td>0.176471</td>
      <td>0.173077</td>
      <td>0.177083</td>
      <td>0.147727</td>
      <td>0.122764</td>
      <td>0.106359</td>
      <td>0.049693</td>
      <td>0.012913</td>
      <td>0.000362</td>
      <td>0.000342</td>
      <td>0.000661</td>
      <td>0.001271</td>
      <td>0.530801</td>
      <td>0.261133</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.153333</td>
      <td>0.175573</td>
      <td>0.176471</td>
      <td>0.163462</td>
      <td>0.156250</td>
      <td>0.136364</td>
      <td>0.142126</td>
      <td>0.142403</td>
      <td>0.031351</td>
      <td>0.003918</td>
      <td>0.000076</td>
      <td>0.000194</td>
      <td>0.000657</td>
      <td>0.001264</td>
      <td>0.682302</td>
      <td>0.536341</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.406667</td>
      <td>0.450382</td>
      <td>0.487395</td>
      <td>0.509615</td>
      <td>0.479167</td>
      <td>0.363636</td>
      <td>0.137472</td>
      <td>0.167497</td>
      <td>0.119614</td>
      <td>0.081188</td>
      <td>0.027106</td>
      <td>0.018571</td>
      <td>0.007043</td>
      <td>0.002509</td>
      <td>0.726836</td>
      <td>0.437973</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.360000</td>
      <td>0.396947</td>
      <td>0.436975</td>
      <td>0.471154</td>
      <td>0.437500</td>
      <td>0.340909</td>
      <td>0.099403</td>
      <td>0.110368</td>
      <td>0.085971</td>
      <td>0.051525</td>
      <td>0.016340</td>
      <td>0.013555</td>
      <td>0.001289</td>
      <td>0.000496</td>
      <td>0.514678</td>
      <td>0.352675</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.286667</td>
      <td>0.328244</td>
      <td>0.361345</td>
      <td>0.384615</td>
      <td>0.395833</td>
      <td>0.295455</td>
      <td>0.043799</td>
      <td>0.051281</td>
      <td>0.003869</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.481936</td>
      <td>0.407122</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1146</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.220000</td>
      <td>0.251908</td>
      <td>0.277311</td>
      <td>0.307692</td>
      <td>0.312500</td>
      <td>0.261364</td>
      <td>0.014179</td>
      <td>0.005609</td>
      <td>0.000294</td>
      <td>0.000052</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.756089</td>
      <td>0.365106</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1147</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.320000</td>
      <td>0.366412</td>
      <td>0.403361</td>
      <td>0.461538</td>
      <td>0.458333</td>
      <td>0.409091</td>
      <td>0.155722</td>
      <td>0.163809</td>
      <td>0.076060</td>
      <td>0.016390</td>
      <td>0.000030</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.663701</td>
      <td>0.410954</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1148</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.320000</td>
      <td>0.358779</td>
      <td>0.394958</td>
      <td>0.423077</td>
      <td>0.437500</td>
      <td>0.363636</td>
      <td>0.074612</td>
      <td>0.083569</td>
      <td>0.016624</td>
      <td>0.002307</td>
      <td>0.000218</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.859281</td>
      <td>0.446002</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1149</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.253333</td>
      <td>0.267176</td>
      <td>0.235294</td>
      <td>0.211538</td>
      <td>0.125000</td>
      <td>0.068182</td>
      <td>0.099548</td>
      <td>0.075419</td>
      <td>0.044696</td>
      <td>0.018030</td>
      <td>0.010958</td>
      <td>0.016263</td>
      <td>0.040346</td>
      <td>0.056559</td>
      <td>0.526653</td>
      <td>0.302456</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1150</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.040000</td>
      <td>0.045802</td>
      <td>0.050420</td>
      <td>0.057692</td>
      <td>0.062500</td>
      <td>0.045455</td>
      <td>0.171150</td>
      <td>0.042074</td>
      <td>0.016504</td>
      <td>0.000780</td>
      <td>0.000412</td>
      <td>0.000422</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.839500</td>
      <td>0.192513</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>1151 rows × 19 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-608d881d-90b8-4a40-bee5-01538deb003c')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-608d881d-90b8-4a40-bee5-01538deb003c button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-608d881d-90b8-4a40-bee5-01538deb003c');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
<p><strong>Save Model Prepocessing</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">filename</span> <span class="o">=</span> <span class="s2">&quot;data_normalisasi.sav&quot;</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">scaler</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;data_normalisasi.sav&#39;]
</pre></div>
</div>
</div>
</div>
<p><strong>Encoding Label</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[b&#39;0&#39;],
       [b&#39;0&#39;],
       [b&#39;1&#39;],
       [b&#39;0&#39;],
       [b&#39;1&#39;]], dtype=object)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>
<span class="n">le</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">le</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>LabelEncoder()
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">LabelEncoder</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>LabelEncoder()
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># testdates = arff.loadarff(&#39;/content/drive/MyDrive/datamining/tugas/messidor_features.arff&#39;)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ybaru</span> <span class="o">=</span> <span class="n">le</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ybaru</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0, 0, 1, ..., 0, 1, 0])
</pre></div>
</div>
</div>
</div>
<p>Pembagian data test mempengaruhi akurasi</p>
<p><strong>Split Dataset</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">training</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">scaled_features</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">training_label</span><span class="p">,</span> <span class="n">test_label</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">ybaru</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="modelling">
<h1><strong>Modelling</strong><a class="headerlink" href="#modelling" title="Permalink to this headline">#</a></h1>
<p><strong>Model Gaussian Naive Bayes</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># library for Naive Bayes Gaussian</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">make_scorer</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span><span class="n">precision_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_score</span><span class="p">,</span><span class="n">recall_score</span><span class="p">,</span><span class="n">f1_score</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>

<span class="c1">#Model Select</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1">#train = data latih &amp; test = data uji</span>
<span class="c1">#train_size dan test_size jika di jumlah harus = 1</span>
<span class="n">training</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">scaled</span><span class="p">,</span> <span class="n">train_size</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">training_label</span><span class="p">,</span> <span class="n">test_label</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">ybaru</span><span class="p">,</span> <span class="n">train_size</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">clf2</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">clf2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">training_label</span><span class="p">)</span>

<span class="n">probas</span> <span class="o">=</span> <span class="n">clf2</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
<span class="n">probas</span> <span class="o">=</span> <span class="n">probas</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">probas</span><span class="o">.</span><span class="n">shape</span>

<span class="n">probas</span>

<span class="n">test_label</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1,
       1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1,
       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1,
       0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0,
       1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0,
       1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,
       0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,
       1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,
       0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,
       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">probas</span> <span class="o">=</span> <span class="n">probas</span><span class="o">.</span><span class="n">round</span><span class="p">()</span>
<span class="n">probas</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
       0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
       0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1.,
       0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
       0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
       1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
       0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
       0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
       1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,
       0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0.,
       1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1.,
       0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0.,
       0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0.,
       1., 1., 1., 0., 1., 0., 1., 1., 1., 0.])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># classifier</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="n">gaussian</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>

<span class="n">gaussian</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">training_label</span><span class="p">)</span>
<span class="n">Y_pred</span> <span class="o">=</span> <span class="n">gaussian</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">)</span> 
<span class="n">accuracy_nb</span><span class="o">=</span><span class="nb">round</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_label</span><span class="p">,</span><span class="n">probas</span><span class="p">)</span><span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">acc_gaussian</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">gaussian</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">training_label</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">test_label</span><span class="p">,</span> <span class="n">probas</span><span class="p">)</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_label</span><span class="p">,</span><span class="n">probas</span><span class="p">)</span>
<span class="n">precision</span> <span class="o">=</span><span class="n">precision_score</span><span class="p">(</span><span class="n">test_label</span><span class="p">,</span> <span class="n">probas</span><span class="p">,</span><span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="n">recall</span> <span class="o">=</span>  <span class="n">recall_score</span><span class="p">(</span><span class="n">test_label</span><span class="p">,</span> <span class="n">probas</span><span class="p">,</span><span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">test_label</span><span class="p">,</span><span class="n">probas</span><span class="p">,</span><span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Confusion matrix for Gaussian Naive Bayes</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span><span class="n">cm</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;accuracy_Gaussian Naive Bayes: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span><span class="k">accuracy</span>)
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;precision_Gaussian Naive Bayes: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span><span class="k">precision</span>)
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;recall_Gaussian Naive Bayes: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span><span class="k">recall</span>)
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;f1-score_random_Forest : </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span><span class="k">f1</span>)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Confusion matrix for Gaussian Naive Bayes
 [[65 50]
 [34 82]]
accuracy_Gaussian Naive Bayes: 0.636
precision_Gaussian Naive Bayes: 0.636
recall_Gaussian Naive Bayes: 0.636
f1-score_random_Forest : 0.636
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#data latih / training</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Data Training : &#39;</span><span class="p">,</span><span class="n">training</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Data Testing : &#39;</span><span class="p">,</span><span class="n">test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data Training :  (920, 19)
Data Testing :  (231, 19)
</pre></div>
</div>
</div>
</div>
<p><strong>Save Model Gaussian Naive Bayes</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">filemodelGaussian</span> <span class="o">=</span> <span class="s1">&#39;model_GaussianNB.pkl&#39;</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">gaussian</span><span class="p">,</span> <span class="n">filemodelGaussian</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;model_GaussianNB.pkl&#39;]
</pre></div>
</div>
</div>
</div>
<p><strong>Model K-NN</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">amount_of_neighbor</span><span class="o">=</span><span class="mi">10</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># classifier</span>
<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">amount_of_neighbor</span><span class="p">)</span>

<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">training_label</span><span class="p">)</span>
<span class="n">Y_pred</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">)</span> 
<span class="n">accuracy_nb</span><span class="o">=</span><span class="nb">round</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_label</span><span class="p">,</span><span class="n">probas</span><span class="p">)</span><span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">acc_knn</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">training_label</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">test_label</span><span class="p">,</span> <span class="n">probas</span><span class="p">)</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_label</span><span class="p">,</span><span class="n">probas</span><span class="p">)</span>
<span class="n">precision</span> <span class="o">=</span><span class="n">precision_score</span><span class="p">(</span><span class="n">test_label</span><span class="p">,</span> <span class="n">probas</span><span class="p">,</span><span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="n">recall</span> <span class="o">=</span>  <span class="n">recall_score</span><span class="p">(</span><span class="n">test_label</span><span class="p">,</span> <span class="n">probas</span><span class="p">,</span><span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">test_label</span><span class="p">,</span><span class="n">probas</span><span class="p">,</span><span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Confusion matrix for Knn</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span><span class="n">cm</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;accuracy_Knn: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span><span class="k">accuracy</span>)
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;precision_Knn: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span><span class="k">precision</span>)
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;recall_Knn: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span><span class="k">recall</span>)
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;f1-score_random_Forest : </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span><span class="k">f1</span>)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Confusion matrix for Knn
 [[65 50]
 [34 82]]
accuracy_Knn: 0.636
precision_Knn: 0.636
recall_Knn: 0.636
f1-score_random_Forest : 0.636
</pre></div>
</div>
</div>
</div>
<p><strong>Save Model KNN</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">filenameModelKnn</span> <span class="o">=</span> <span class="s1">&#39;model_Knn.pkl&#39;</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">knn</span><span class="p">,</span> <span class="n">filenameModelKnn</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;model_Knn.pkl&#39;]
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="bagging-classifier">
<h1><strong>Bagging Classifier</strong><a class="headerlink" href="#bagging-classifier" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gaussian</span> <span class="o">=</span> <span class="n">gaussian</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">training_label</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">training_pred</span> <span class="o">=</span> <span class="n">gaussian</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">training</span><span class="p">)</span>
<span class="n">testing_pred</span> <span class="o">=</span> <span class="n">gaussian</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf_training</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">training_label</span><span class="p">,</span> <span class="n">training_pred</span><span class="p">)</span>
<span class="n">clf_test</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_label</span><span class="p">,</span> <span class="n">testing_pred</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Gaussian Training&quot;</span><span class="p">,</span><span class="n">clf_training</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Gaussian Testing&quot;</span><span class="p">,</span><span class="n">clf_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Gaussian Training 0.6293478260869565
Gaussian Testing 0.6363636363636364
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingClassifier</span>
<span class="n">n</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">500</span><span class="p">))</span>
<span class="n">acuracy</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">n</span><span class="p">:</span>
  <span class="n">bag</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span>
          <span class="n">base_estimator</span><span class="o">=</span><span class="n">gaussian</span><span class="p">,</span> <span class="c1"># knn,gnb, jst</span>
          <span class="n">n_estimators</span><span class="o">=</span><span class="n">i</span><span class="p">,</span>
          <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">bag</span> <span class="o">=</span> <span class="n">bag</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">training_label</span><span class="p">)</span>
  <span class="n">y_test_pred</span> <span class="o">=</span> <span class="n">bag</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
  <span class="n">bag_test</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_label</span><span class="p">,</span> <span class="n">y_test_pred</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;acuracy n = </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1"> = </span><span class="si">{</span><span class="n">bag_test</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
  <span class="n">acuracy</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bag_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 2 = 0.6363636363636364
acuracy n = 3 = 0.6363636363636364
acuracy n = 4 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 5 = 0.6233766233766234
acuracy n = 6 = 0.6493506493506493
acuracy n = 7 = 0.6406926406926406
acuracy n = 8 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 9 = 0.6406926406926406
acuracy n = 10 = 0.6320346320346321
acuracy n = 11 = 0.6406926406926406
acuracy n = 12 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 13 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 14 = 0.6320346320346321
acuracy n = 15 = 0.6320346320346321
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 16 = 0.6363636363636364
acuracy n = 17 = 0.6277056277056277
acuracy n = 18 = 0.6277056277056277
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 19 = 0.6277056277056277
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 20 = 0.6277056277056277
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 21 = 0.6277056277056277
acuracy n = 22 = 0.6363636363636364
acuracy n = 23 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 24 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 25 = 0.6406926406926406
acuracy n = 26 = 0.6406926406926406
acuracy n = 27 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 28 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 29 = 0.6406926406926406
acuracy n = 30 = 0.6406926406926406
acuracy n = 31 = 0.6493506493506493
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 32 = 0.645021645021645
acuracy n = 33 = 0.6493506493506493
acuracy n = 34 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 35 = 0.6493506493506493
acuracy n = 36 = 0.6493506493506493
acuracy n = 37 = 0.6536796536796536
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 38 = 0.6493506493506493
acuracy n = 39 = 0.6493506493506493
acuracy n = 40 = 0.6493506493506493
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 41 = 0.6536796536796536
acuracy n = 42 = 0.6536796536796536
acuracy n = 43 = 0.6536796536796536
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 44 = 0.645021645021645
acuracy n = 45 = 0.6406926406926406
acuracy n = 46 = 0.6493506493506493
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 47 = 0.6406926406926406
acuracy n = 48 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 49 = 0.6406926406926406
acuracy n = 50 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 51 = 0.6406926406926406
acuracy n = 52 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 53 = 0.6406926406926406
acuracy n = 54 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 55 = 0.6406926406926406
acuracy n = 56 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 57 = 0.6406926406926406
acuracy n = 58 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 59 = 0.6406926406926406
acuracy n = 60 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 61 = 0.645021645021645
acuracy n = 62 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 63 = 0.6406926406926406
acuracy n = 64 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 65 = 0.645021645021645
acuracy n = 66 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 67 = 0.6493506493506493
acuracy n = 68 = 0.6536796536796536
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 69 = 0.6536796536796536
acuracy n = 70 = 0.6493506493506493
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 71 = 0.6493506493506493
acuracy n = 72 = 0.6536796536796536
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 73 = 0.6493506493506493
acuracy n = 74 = 0.6493506493506493
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 75 = 0.645021645021645
acuracy n = 76 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 77 = 0.6406926406926406
acuracy n = 78 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 79 = 0.6406926406926406
acuracy n = 80 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 81 = 0.6406926406926406
acuracy n = 82 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 83 = 0.6406926406926406
acuracy n = 84 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 85 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 86 = 0.6406926406926406
acuracy n = 87 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 88 = 0.6406926406926406
acuracy n = 89 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 90 = 0.645021645021645
acuracy n = 91 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 92 = 0.645021645021645
acuracy n = 93 = 0.6493506493506493
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 94 = 0.6493506493506493
acuracy n = 95 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 96 = 0.645021645021645
acuracy n = 97 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 98 = 0.6406926406926406
acuracy n = 99 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 100 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 101 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 102 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 103 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 104 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 105 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 106 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 107 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 108 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 109 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 110 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 111 = 0.6493506493506493
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 112 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 113 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 114 = 0.6493506493506493
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 115 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 116 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 117 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 118 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 119 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 120 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 121 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 122 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 123 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 124 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 125 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 126 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 127 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 128 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 129 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 130 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 131 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 132 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 133 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 134 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 135 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 136 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 137 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 138 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 139 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 140 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 141 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 142 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 143 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 144 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 145 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 146 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 147 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 148 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 149 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 150 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 151 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 152 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 153 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 154 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 155 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 156 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 157 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 158 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 159 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 160 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 161 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 162 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 163 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 164 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 165 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 166 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 167 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 168 = 0.6363636363636364
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="ne">KeyboardInterrupt</span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">27</span><span class="o">-</span><span class="n">be82bc34d1b3</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span>           <span class="n">n_estimators</span><span class="o">=</span><span class="n">i</span><span class="p">,</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span>           <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="ne">----&gt; </span><span class="mi">9</span>   <span class="n">bag</span> <span class="o">=</span> <span class="n">bag</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">training_label</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">10</span>   <span class="n">y_test_pred</span> <span class="o">=</span> <span class="n">bag</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">11</span>   <span class="n">bag_test</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_label</span><span class="p">,</span> <span class="n">y_test_pred</span><span class="p">)</span>

<span class="nn">/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_bagging.py</span> in <span class="ni">fit</span><span class="nt">(self, X, y, sample_weight)</span>
<span class="g g-Whitespace">    </span><span class="mi">267</span>             <span class="n">multi_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">268</span>         <span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">269</span>         <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_samples</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">270</span> 
<span class="g g-Whitespace">    </span><span class="mi">271</span>     <span class="k">def</span> <span class="nf">_parallel_args</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

<span class="nn">/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_bagging.py</span> in <span class="ni">_fit</span><span class="nt">(self, X, y, max_samples, max_depth, sample_weight)</span>
<span class="g g-Whitespace">    </span><span class="mi">405</span>                 <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">406</span>             <span class="p">)</span>
<span class="nn">--&gt; 407             for i</span> in <span class="ni">range</span><span class="nt">(n_jobs)</span>
<span class="g g-Whitespace">    </span><span class="mi">408</span>         <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">409</span> 

<span class="nn">/usr/local/lib/python3.7/dist-packages/joblib/parallel.py</span> in <span class="ni">__call__</span><span class="nt">(self, iterable)</span>
<span class="g g-Whitespace">   </span><span class="mi">1083</span>             <span class="c1"># remaining jobs.</span>
<span class="g g-Whitespace">   </span><span class="mi">1084</span>             <span class="bp">self</span><span class="o">.</span><span class="n">_iterating</span> <span class="o">=</span> <span class="kc">False</span>
<span class="ne">-&gt; </span><span class="mi">1085</span>             <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dispatch_one_batch</span><span class="p">(</span><span class="n">iterator</span><span class="p">):</span>
<span class="g g-Whitespace">   </span><span class="mi">1086</span>                 <span class="bp">self</span><span class="o">.</span><span class="n">_iterating</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_original_iterator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
<span class="g g-Whitespace">   </span><span class="mi">1087</span> 

<span class="nn">/usr/local/lib/python3.7/dist-packages/joblib/parallel.py</span> in <span class="ni">dispatch_one_batch</span><span class="nt">(self, iterator)</span>
<span class="g g-Whitespace">    </span><span class="mi">899</span>                 <span class="k">return</span> <span class="kc">False</span>
<span class="g g-Whitespace">    </span><span class="mi">900</span>             <span class="k">else</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">901</span>                 <span class="bp">self</span><span class="o">.</span><span class="n">_dispatch</span><span class="p">(</span><span class="n">tasks</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">902</span>                 <span class="k">return</span> <span class="kc">True</span>
<span class="g g-Whitespace">    </span><span class="mi">903</span> 

<span class="nn">/usr/local/lib/python3.7/dist-packages/joblib/parallel.py</span> in <span class="ni">_dispatch</span><span class="nt">(self, batch)</span>
<span class="g g-Whitespace">    </span><span class="mi">817</span>         <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lock</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">818</span>             <span class="n">job_idx</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_jobs</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">819</span>             <span class="n">job</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backend</span><span class="o">.</span><span class="n">apply_async</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="n">cb</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">820</span>             <span class="c1"># A job can complete so quickly than its callback is</span>
<span class="g g-Whitespace">    </span><span class="mi">821</span>             <span class="c1"># called before we get here, causing self._jobs to</span>

<span class="nn">/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py</span> in <span class="ni">apply_async</span><span class="nt">(self, func, callback)</span>
<span class="g g-Whitespace">    </span><span class="mi">206</span>     <span class="k">def</span> <span class="nf">apply_async</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">207</span>         <span class="sd">&quot;&quot;&quot;Schedule a func to be run&quot;&quot;&quot;</span>
<span class="ne">--&gt; </span><span class="mi">208</span>         <span class="n">result</span> <span class="o">=</span> <span class="n">ImmediateResult</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">209</span>         <span class="k">if</span> <span class="n">callback</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">210</span>             <span class="n">callback</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

<span class="nn">/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py</span> in <span class="ni">__init__</span><span class="nt">(self, batch)</span>
<span class="g g-Whitespace">    </span><span class="mi">595</span>         <span class="c1"># Don&#39;t delay the application, to avoid keeping the input</span>
<span class="g g-Whitespace">    </span><span class="mi">596</span>         <span class="c1"># arguments in memory</span>
<span class="ne">--&gt; </span><span class="mi">597</span>         <span class="bp">self</span><span class="o">.</span><span class="n">results</span> <span class="o">=</span> <span class="n">batch</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">598</span> 
<span class="g g-Whitespace">    </span><span class="mi">599</span>     <span class="k">def</span> <span class="nf">get</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

<span class="nn">/usr/local/lib/python3.7/dist-packages/joblib/parallel.py</span> in <span class="ni">__call__</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">287</span>         <span class="k">with</span> <span class="n">parallel_backend</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backend</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_jobs</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">288</span>             <span class="k">return</span> <span class="p">[</span><span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">289</span>                     <span class="k">for</span> <span class="n">func</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">]</span>
<span class="g g-Whitespace">    </span><span class="mi">290</span> 
<span class="g g-Whitespace">    </span><span class="mi">291</span>     <span class="k">def</span> <span class="nf">__reduce__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

<span class="nn">/usr/local/lib/python3.7/dist-packages/joblib/parallel.py</span> in <span class="ni">&lt;listcomp&gt;</span><span class="nt">(.0)</span>
<span class="g g-Whitespace">    </span><span class="mi">287</span>         <span class="k">with</span> <span class="n">parallel_backend</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backend</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_jobs</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">288</span>             <span class="k">return</span> <span class="p">[</span><span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">289</span>                     <span class="k">for</span> <span class="n">func</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">]</span>
<span class="g g-Whitespace">    </span><span class="mi">290</span> 
<span class="g g-Whitespace">    </span><span class="mi">291</span>     <span class="k">def</span> <span class="nf">__reduce__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

<span class="nn">/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py</span> in <span class="ni">__call__</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">214</span>     <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">215</span>         <span class="k">with</span> <span class="n">config_context</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">216</span>             <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">217</span> 
<span class="g g-Whitespace">    </span><span class="mi">218</span> 

<span class="nn">/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_bagging.py</span> in <span class="ni">_parallel_build_estimators</span><span class="nt">(n_estimators, ensemble, X, y, sample_weight, seeds, total_n_estimators, verbose)</span>
<span class="g g-Whitespace">    </span><span class="mi">104</span>             <span class="n">n_samples</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">105</span>             <span class="n">max_features</span><span class="p">,</span>
<span class="ne">--&gt; </span><span class="mi">106</span>             <span class="n">max_samples</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">107</span>         <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">108</span> 

<span class="nn">/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_bagging.py</span> in <span class="ni">_generate_bagging_indices</span><span class="nt">(random_state, bootstrap_features, bootstrap_samples, n_features, n_samples, max_features, max_samples)</span>
<span class="g g-Whitespace">     </span><span class="mi">62</span>     <span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">63</span>     <span class="n">sample_indices</span> <span class="o">=</span> <span class="n">_generate_indices</span><span class="p">(</span>
<span class="ne">---&gt; </span><span class="mi">64</span>         <span class="n">random_state</span><span class="p">,</span> <span class="n">bootstrap_samples</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">max_samples</span>
<span class="g g-Whitespace">     </span><span class="mi">65</span>     <span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">66</span> 

<span class="nn">/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_bagging.py</span> in <span class="ni">_generate_indices</span><span class="nt">(random_state, bootstrap, n_population, n_samples)</span>
<span class="g g-Whitespace">     </span><span class="mi">35</span>     <span class="c1"># Draw sample indices</span>
<span class="g g-Whitespace">     </span><span class="mi">36</span>     <span class="k">if</span> <span class="n">bootstrap</span><span class="p">:</span>
<span class="ne">---&gt; </span><span class="mi">37</span>         <span class="n">indices</span> <span class="o">=</span> <span class="n">random_state</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_population</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">38</span>     <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">39</span>         <span class="n">indices</span> <span class="o">=</span> <span class="n">sample_without_replacement</span><span class="p">(</span>

<span class="nn">mtrand.pyx</span> in <span class="ni">numpy.random.mtrand.RandomState.randint</span><span class="nt">()</span>

<span class="nn">_bounded_integers.pyx</span> in <span class="ni">numpy.random._bounded_integers._rand_int64</span><span class="nt">()</span>

<span class="nn">&lt;__array_function__ internals&gt;</span> in <span class="ni">prod</span><span class="nt">(*args, **kwargs)</span>

<span class="nn">/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py</span> in <span class="ni">prod</span><span class="nt">(a, axis, dtype, out, keepdims, initial, where)</span>
<span class="g g-Whitespace">   </span><span class="mi">3050</span>     <span class="s2">&quot;&quot;&quot;</span>
<span class="g g-Whitespace">   </span><span class="mi">3051</span><span class="s2">     return _wrapreduction(a, np.multiply, &#39;prod&#39;, axis, dtype, out,</span>
<span class="ne">-&gt; </span><span class="mi">3052</span><span class="s2">                           keepdims=keepdims, initial=initial, where=where)</span>
<span class="g g-Whitespace">   </span><span class="mi">3053</span><span class="s2"> </span>
<span class="g g-Whitespace">   </span><span class="mi">3054</span><span class="s2"> </span>

<span class="nn">/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py</span> in <span class="ni">_wrapreduction</span><span class="nt">(obj, ufunc, method, axis, dtype, out, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">84</span><span class="s2">                 return reduction(axis=axis, out=out, **passkwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">85</span><span class="s2"> </span>
<span class="ne">---&gt; </span><span class="mi">86</span><span class="s2">     return ufunc.reduce(obj, axis, dtype, out, **passkwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">87</span><span class="s2"> </span>
<span class="g g-Whitespace">     </span><span class="mi">88</span><span class="s2"> </span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="c1"># n = list(range(2,500))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">acuracy</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Tugas 7_41_0.png" src="_images/Tugas 7_41_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">max</span><span class="p">(</span><span class="n">acuracy</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.6536796536796536
</pre></div>
</div>
</div>
</div>
<p><strong>Random Forest</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># bag = bag.fit(X_train, y_train)</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">training_label</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">500</span><span class="p">))</span>
<span class="n">acuracy</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">n</span><span class="p">:</span>
  <span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">training_label</span><span class="p">)</span>
  <span class="n">y_test_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
  <span class="n">bag_test</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_label</span><span class="p">,</span> <span class="n">y_test_pred</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;acuracy n = </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1"> = </span><span class="si">{</span><span class="n">bag_test</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
  <span class="n">acuracy</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bag_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 2 = 0.6623376623376623
acuracy n = 3 = 0.6536796536796536
acuracy n = 4 = 0.6536796536796536
acuracy n = 5 = 0.645021645021645
acuracy n = 6 = 0.6493506493506493
acuracy n = 7 = 0.645021645021645
acuracy n = 8 = 0.6493506493506493
acuracy n = 9 = 0.6493506493506493
acuracy n = 10 = 0.658008658008658
acuracy n = 11 = 0.6623376623376623
acuracy n = 12 = 0.6493506493506493
acuracy n = 13 = 0.6406926406926406
acuracy n = 14 = 0.658008658008658
acuracy n = 15 = 0.6666666666666666
acuracy n = 16 = 0.6493506493506493
acuracy n = 17 = 0.6536796536796536
acuracy n = 18 = 0.6493506493506493
acuracy n = 19 = 0.6406926406926406
acuracy n = 20 = 0.6406926406926406
acuracy n = 21 = 0.6406926406926406
acuracy n = 22 = 0.6493506493506493
acuracy n = 23 = 0.6406926406926406
acuracy n = 24 = 0.645021645021645
acuracy n = 25 = 0.6406926406926406
acuracy n = 26 = 0.6406926406926406
acuracy n = 27 = 0.6406926406926406
acuracy n = 28 = 0.6406926406926406
acuracy n = 29 = 0.645021645021645
acuracy n = 30 = 0.645021645021645
acuracy n = 31 = 0.6493506493506493
acuracy n = 32 = 0.6493506493506493
acuracy n = 33 = 0.6493506493506493
acuracy n = 34 = 0.6493506493506493
acuracy n = 35 = 0.6493506493506493
acuracy n = 36 = 0.6493506493506493
acuracy n = 37 = 0.6493506493506493
acuracy n = 38 = 0.6493506493506493
acuracy n = 39 = 0.6493506493506493
acuracy n = 40 = 0.6493506493506493
acuracy n = 41 = 0.658008658008658
acuracy n = 42 = 0.658008658008658
acuracy n = 43 = 0.658008658008658
acuracy n = 44 = 0.6536796536796536
acuracy n = 45 = 0.658008658008658
acuracy n = 46 = 0.6536796536796536
acuracy n = 47 = 0.658008658008658
acuracy n = 48 = 0.658008658008658
acuracy n = 49 = 0.658008658008658
acuracy n = 50 = 0.658008658008658
acuracy n = 51 = 0.658008658008658
acuracy n = 52 = 0.658008658008658
acuracy n = 53 = 0.658008658008658
acuracy n = 54 = 0.658008658008658
acuracy n = 55 = 0.658008658008658
acuracy n = 56 = 0.658008658008658
acuracy n = 57 = 0.6536796536796536
acuracy n = 58 = 0.6536796536796536
acuracy n = 59 = 0.6493506493506493
acuracy n = 60 = 0.658008658008658
acuracy n = 61 = 0.658008658008658
acuracy n = 62 = 0.6493506493506493
acuracy n = 63 = 0.6536796536796536
acuracy n = 64 = 0.6623376623376623
acuracy n = 65 = 0.6623376623376623
acuracy n = 66 = 0.6623376623376623
acuracy n = 67 = 0.658008658008658
acuracy n = 68 = 0.658008658008658
acuracy n = 69 = 0.658008658008658
acuracy n = 70 = 0.658008658008658
acuracy n = 71 = 0.6623376623376623
acuracy n = 72 = 0.6623376623376623
acuracy n = 73 = 0.6623376623376623
acuracy n = 74 = 0.6623376623376623
acuracy n = 75 = 0.6623376623376623
acuracy n = 76 = 0.6623376623376623
acuracy n = 77 = 0.6623376623376623
acuracy n = 78 = 0.6623376623376623
acuracy n = 79 = 0.6666666666666666
acuracy n = 80 = 0.6666666666666666
acuracy n = 81 = 0.6666666666666666
acuracy n = 82 = 0.6666666666666666
acuracy n = 83 = 0.6666666666666666
acuracy n = 84 = 0.6666666666666666
acuracy n = 85 = 0.6623376623376623
acuracy n = 86 = 0.6623376623376623
acuracy n = 87 = 0.658008658008658
acuracy n = 88 = 0.6623376623376623
acuracy n = 89 = 0.658008658008658
acuracy n = 90 = 0.6623376623376623
acuracy n = 91 = 0.658008658008658
acuracy n = 92 = 0.658008658008658
acuracy n = 93 = 0.6623376623376623
acuracy n = 94 = 0.658008658008658
acuracy n = 95 = 0.658008658008658
acuracy n = 96 = 0.658008658008658
acuracy n = 97 = 0.658008658008658
acuracy n = 98 = 0.658008658008658
acuracy n = 99 = 0.658008658008658
acuracy n = 100 = 0.658008658008658
acuracy n = 101 = 0.658008658008658
acuracy n = 102 = 0.658008658008658
acuracy n = 103 = 0.658008658008658
acuracy n = 104 = 0.6536796536796536
acuracy n = 105 = 0.6536796536796536
acuracy n = 106 = 0.6536796536796536
acuracy n = 107 = 0.6536796536796536
acuracy n = 108 = 0.6536796536796536
acuracy n = 109 = 0.6536796536796536
acuracy n = 110 = 0.6536796536796536
acuracy n = 111 = 0.6536796536796536
acuracy n = 112 = 0.6536796536796536
acuracy n = 113 = 0.6536796536796536
acuracy n = 114 = 0.6536796536796536
acuracy n = 115 = 0.6536796536796536
acuracy n = 116 = 0.6536796536796536
acuracy n = 117 = 0.6536796536796536
acuracy n = 118 = 0.6536796536796536
acuracy n = 119 = 0.6536796536796536
acuracy n = 120 = 0.6536796536796536
acuracy n = 121 = 0.6536796536796536
acuracy n = 122 = 0.6536796536796536
acuracy n = 123 = 0.6536796536796536
acuracy n = 124 = 0.6536796536796536
acuracy n = 125 = 0.6536796536796536
acuracy n = 126 = 0.6536796536796536
acuracy n = 127 = 0.6536796536796536
acuracy n = 128 = 0.6493506493506493
acuracy n = 129 = 0.6493506493506493
acuracy n = 130 = 0.6493506493506493
acuracy n = 131 = 0.6493506493506493
acuracy n = 132 = 0.6536796536796536
acuracy n = 133 = 0.6493506493506493
acuracy n = 134 = 0.6493506493506493
acuracy n = 135 = 0.6536796536796536
acuracy n = 136 = 0.6536796536796536
acuracy n = 137 = 0.6493506493506493
acuracy n = 138 = 0.6536796536796536
acuracy n = 139 = 0.6536796536796536
acuracy n = 140 = 0.6536796536796536
acuracy n = 141 = 0.6536796536796536
acuracy n = 142 = 0.6493506493506493
acuracy n = 143 = 0.6536796536796536
acuracy n = 144 = 0.6536796536796536
acuracy n = 145 = 0.6536796536796536
acuracy n = 146 = 0.658008658008658
acuracy n = 147 = 0.6536796536796536
acuracy n = 148 = 0.6536796536796536
acuracy n = 149 = 0.6536796536796536
acuracy n = 150 = 0.6536796536796536
acuracy n = 151 = 0.6536796536796536
acuracy n = 152 = 0.6536796536796536
acuracy n = 153 = 0.6536796536796536
acuracy n = 154 = 0.6536796536796536
acuracy n = 155 = 0.6536796536796536
acuracy n = 156 = 0.6536796536796536
acuracy n = 157 = 0.6493506493506493
acuracy n = 158 = 0.6493506493506493
acuracy n = 159 = 0.6493506493506493
acuracy n = 160 = 0.6493506493506493
acuracy n = 161 = 0.6493506493506493
acuracy n = 162 = 0.6493506493506493
acuracy n = 163 = 0.6493506493506493
acuracy n = 164 = 0.6493506493506493
acuracy n = 165 = 0.6536796536796536
acuracy n = 166 = 0.6493506493506493
acuracy n = 167 = 0.6536796536796536
acuracy n = 168 = 0.6536796536796536
acuracy n = 169 = 0.6536796536796536
acuracy n = 170 = 0.6536796536796536
acuracy n = 171 = 0.6536796536796536
acuracy n = 172 = 0.6493506493506493
acuracy n = 173 = 0.6493506493506493
acuracy n = 174 = 0.6493506493506493
acuracy n = 175 = 0.6493506493506493
acuracy n = 176 = 0.6536796536796536
acuracy n = 177 = 0.6493506493506493
acuracy n = 178 = 0.6493506493506493
acuracy n = 179 = 0.645021645021645
acuracy n = 180 = 0.6493506493506493
acuracy n = 181 = 0.6493506493506493
acuracy n = 182 = 0.6493506493506493
acuracy n = 183 = 0.6406926406926406
acuracy n = 184 = 0.6493506493506493
acuracy n = 185 = 0.6493506493506493
acuracy n = 186 = 0.645021645021645
acuracy n = 187 = 0.645021645021645
acuracy n = 188 = 0.6493506493506493
acuracy n = 189 = 0.6493506493506493
acuracy n = 190 = 0.6493506493506493
acuracy n = 191 = 0.6493506493506493
acuracy n = 192 = 0.6493506493506493
acuracy n = 193 = 0.6493506493506493
acuracy n = 194 = 0.6493506493506493
acuracy n = 195 = 0.645021645021645
acuracy n = 196 = 0.645021645021645
acuracy n = 197 = 0.645021645021645
acuracy n = 198 = 0.6406926406926406
acuracy n = 199 = 0.6406926406926406
acuracy n = 200 = 0.6406926406926406
acuracy n = 201 = 0.6363636363636364
acuracy n = 202 = 0.6363636363636364
acuracy n = 203 = 0.6406926406926406
acuracy n = 204 = 0.6406926406926406
acuracy n = 205 = 0.6406926406926406
acuracy n = 206 = 0.6406926406926406
acuracy n = 207 = 0.6406926406926406
acuracy n = 208 = 0.6406926406926406
acuracy n = 209 = 0.6406926406926406
acuracy n = 210 = 0.6406926406926406
acuracy n = 211 = 0.6406926406926406
acuracy n = 212 = 0.6406926406926406
acuracy n = 213 = 0.6406926406926406
acuracy n = 214 = 0.6406926406926406
acuracy n = 215 = 0.6406926406926406
acuracy n = 216 = 0.6406926406926406
acuracy n = 217 = 0.6363636363636364
acuracy n = 218 = 0.6363636363636364
acuracy n = 219 = 0.6363636363636364
acuracy n = 220 = 0.6363636363636364
acuracy n = 221 = 0.6363636363636364
acuracy n = 222 = 0.6363636363636364
acuracy n = 223 = 0.6363636363636364
acuracy n = 224 = 0.6363636363636364
acuracy n = 225 = 0.6406926406926406
acuracy n = 226 = 0.6406926406926406
acuracy n = 227 = 0.6406926406926406
acuracy n = 228 = 0.6406926406926406
acuracy n = 229 = 0.6406926406926406
acuracy n = 230 = 0.6406926406926406
acuracy n = 231 = 0.6406926406926406
acuracy n = 232 = 0.6406926406926406
acuracy n = 233 = 0.6406926406926406
acuracy n = 234 = 0.6406926406926406
acuracy n = 235 = 0.6406926406926406
acuracy n = 236 = 0.6363636363636364
acuracy n = 237 = 0.6363636363636364
acuracy n = 238 = 0.6363636363636364
acuracy n = 239 = 0.6406926406926406
acuracy n = 240 = 0.6363636363636364
acuracy n = 241 = 0.6406926406926406
acuracy n = 242 = 0.6406926406926406
acuracy n = 243 = 0.6406926406926406
acuracy n = 244 = 0.6406926406926406
acuracy n = 245 = 0.6406926406926406
acuracy n = 246 = 0.6406926406926406
acuracy n = 247 = 0.6406926406926406
acuracy n = 248 = 0.6406926406926406
acuracy n = 249 = 0.6406926406926406
acuracy n = 250 = 0.6406926406926406
acuracy n = 251 = 0.6363636363636364
acuracy n = 252 = 0.6406926406926406
acuracy n = 253 = 0.6406926406926406
acuracy n = 254 = 0.6406926406926406
acuracy n = 255 = 0.6406926406926406
acuracy n = 256 = 0.6406926406926406
acuracy n = 257 = 0.6363636363636364
acuracy n = 258 = 0.6406926406926406
acuracy n = 259 = 0.6406926406926406
acuracy n = 260 = 0.6363636363636364
acuracy n = 261 = 0.6363636363636364
acuracy n = 262 = 0.6363636363636364
acuracy n = 263 = 0.6363636363636364
acuracy n = 264 = 0.6363636363636364
acuracy n = 265 = 0.6363636363636364
acuracy n = 266 = 0.6363636363636364
acuracy n = 267 = 0.6363636363636364
acuracy n = 268 = 0.6363636363636364
acuracy n = 269 = 0.6406926406926406
acuracy n = 270 = 0.6406926406926406
acuracy n = 271 = 0.6363636363636364
acuracy n = 272 = 0.6363636363636364
acuracy n = 273 = 0.6363636363636364
acuracy n = 274 = 0.6363636363636364
acuracy n = 275 = 0.6363636363636364
acuracy n = 276 = 0.6363636363636364
acuracy n = 277 = 0.6363636363636364
acuracy n = 278 = 0.6363636363636364
acuracy n = 279 = 0.6363636363636364
acuracy n = 280 = 0.6363636363636364
acuracy n = 281 = 0.6363636363636364
acuracy n = 282 = 0.6363636363636364
acuracy n = 283 = 0.6363636363636364
acuracy n = 284 = 0.6363636363636364
acuracy n = 285 = 0.6363636363636364
acuracy n = 286 = 0.6363636363636364
acuracy n = 287 = 0.6363636363636364
acuracy n = 288 = 0.6406926406926406
acuracy n = 289 = 0.6406926406926406
acuracy n = 290 = 0.6406926406926406
acuracy n = 291 = 0.6406926406926406
acuracy n = 292 = 0.6406926406926406
acuracy n = 293 = 0.6406926406926406
acuracy n = 294 = 0.6406926406926406
acuracy n = 295 = 0.6406926406926406
acuracy n = 296 = 0.6406926406926406
acuracy n = 297 = 0.6406926406926406
acuracy n = 298 = 0.6406926406926406
acuracy n = 299 = 0.6406926406926406
acuracy n = 300 = 0.6406926406926406
acuracy n = 301 = 0.6406926406926406
acuracy n = 302 = 0.6406926406926406
acuracy n = 303 = 0.6406926406926406
acuracy n = 304 = 0.6363636363636364
acuracy n = 305 = 0.6363636363636364
acuracy n = 306 = 0.6363636363636364
acuracy n = 307 = 0.6363636363636364
acuracy n = 308 = 0.6406926406926406
acuracy n = 309 = 0.6406926406926406
acuracy n = 310 = 0.6406926406926406
acuracy n = 311 = 0.6406926406926406
acuracy n = 312 = 0.6406926406926406
acuracy n = 313 = 0.6363636363636364
acuracy n = 314 = 0.6363636363636364
acuracy n = 315 = 0.6406926406926406
acuracy n = 316 = 0.6406926406926406
acuracy n = 317 = 0.6363636363636364
acuracy n = 318 = 0.6363636363636364
acuracy n = 319 = 0.6363636363636364
acuracy n = 320 = 0.6363636363636364
acuracy n = 321 = 0.6363636363636364
acuracy n = 322 = 0.6363636363636364
acuracy n = 323 = 0.6363636363636364
acuracy n = 324 = 0.6363636363636364
acuracy n = 325 = 0.6406926406926406
acuracy n = 326 = 0.6406926406926406
acuracy n = 327 = 0.6406926406926406
acuracy n = 328 = 0.6363636363636364
acuracy n = 329 = 0.6363636363636364
acuracy n = 330 = 0.6363636363636364
acuracy n = 331 = 0.6406926406926406
acuracy n = 332 = 0.6406926406926406
acuracy n = 333 = 0.6406926406926406
acuracy n = 334 = 0.6406926406926406
acuracy n = 335 = 0.6406926406926406
acuracy n = 336 = 0.6406926406926406
acuracy n = 337 = 0.6406926406926406
acuracy n = 338 = 0.6406926406926406
acuracy n = 339 = 0.6406926406926406
acuracy n = 340 = 0.6363636363636364
acuracy n = 341 = 0.6406926406926406
acuracy n = 342 = 0.6406926406926406
acuracy n = 343 = 0.6406926406926406
acuracy n = 344 = 0.6406926406926406
acuracy n = 345 = 0.6406926406926406
acuracy n = 346 = 0.6406926406926406
acuracy n = 347 = 0.6363636363636364
acuracy n = 348 = 0.6406926406926406
acuracy n = 349 = 0.6406926406926406
acuracy n = 350 = 0.6406926406926406
acuracy n = 351 = 0.6406926406926406
acuracy n = 352 = 0.6406926406926406
acuracy n = 353 = 0.6406926406926406
acuracy n = 354 = 0.6406926406926406
acuracy n = 355 = 0.6406926406926406
acuracy n = 356 = 0.6406926406926406
acuracy n = 357 = 0.6406926406926406
acuracy n = 358 = 0.6406926406926406
acuracy n = 359 = 0.6406926406926406
acuracy n = 360 = 0.6406926406926406
acuracy n = 361 = 0.6406926406926406
acuracy n = 362 = 0.6363636363636364
acuracy n = 363 = 0.6363636363636364
acuracy n = 364 = 0.6406926406926406
acuracy n = 365 = 0.6320346320346321
acuracy n = 366 = 0.6320346320346321
acuracy n = 367 = 0.6320346320346321
acuracy n = 368 = 0.6320346320346321
acuracy n = 369 = 0.6320346320346321
acuracy n = 370 = 0.6363636363636364
acuracy n = 371 = 0.6363636363636364
acuracy n = 372 = 0.6363636363636364
acuracy n = 373 = 0.6363636363636364
acuracy n = 374 = 0.6363636363636364
acuracy n = 375 = 0.6363636363636364
acuracy n = 376 = 0.6363636363636364
acuracy n = 377 = 0.6363636363636364
acuracy n = 378 = 0.6363636363636364
acuracy n = 379 = 0.6406926406926406
acuracy n = 380 = 0.6406926406926406
acuracy n = 381 = 0.6406926406926406
acuracy n = 382 = 0.6363636363636364
acuracy n = 383 = 0.6320346320346321
acuracy n = 384 = 0.6363636363636364
acuracy n = 385 = 0.6406926406926406
acuracy n = 386 = 0.6320346320346321
acuracy n = 387 = 0.6363636363636364
acuracy n = 388 = 0.6363636363636364
acuracy n = 389 = 0.6363636363636364
acuracy n = 390 = 0.6363636363636364
acuracy n = 391 = 0.6363636363636364
acuracy n = 392 = 0.6363636363636364
acuracy n = 393 = 0.6363636363636364
acuracy n = 394 = 0.6363636363636364
acuracy n = 395 = 0.6363636363636364
acuracy n = 396 = 0.6406926406926406
acuracy n = 397 = 0.6406926406926406
acuracy n = 398 = 0.6363636363636364
acuracy n = 399 = 0.6363636363636364
acuracy n = 400 = 0.6363636363636364
acuracy n = 401 = 0.6363636363636364
acuracy n = 402 = 0.6406926406926406
acuracy n = 403 = 0.6406926406926406
acuracy n = 404 = 0.6320346320346321
acuracy n = 405 = 0.6363636363636364
acuracy n = 406 = 0.6363636363636364
acuracy n = 407 = 0.6363636363636364
acuracy n = 408 = 0.6363636363636364
acuracy n = 409 = 0.6363636363636364
acuracy n = 410 = 0.6363636363636364
acuracy n = 411 = 0.6363636363636364
acuracy n = 412 = 0.6363636363636364
acuracy n = 413 = 0.6406926406926406
acuracy n = 414 = 0.6363636363636364
acuracy n = 415 = 0.6363636363636364
acuracy n = 416 = 0.6363636363636364
acuracy n = 417 = 0.6363636363636364
acuracy n = 418 = 0.6363636363636364
acuracy n = 419 = 0.6406926406926406
acuracy n = 420 = 0.6406926406926406
acuracy n = 421 = 0.6406926406926406
acuracy n = 422 = 0.6406926406926406
acuracy n = 423 = 0.6406926406926406
acuracy n = 424 = 0.6406926406926406
acuracy n = 425 = 0.6406926406926406
acuracy n = 426 = 0.6406926406926406
acuracy n = 427 = 0.6406926406926406
acuracy n = 428 = 0.6406926406926406
acuracy n = 429 = 0.6406926406926406
acuracy n = 430 = 0.6406926406926406
acuracy n = 431 = 0.6406926406926406
acuracy n = 432 = 0.6406926406926406
acuracy n = 433 = 0.6363636363636364
acuracy n = 434 = 0.6363636363636364
acuracy n = 435 = 0.6363636363636364
acuracy n = 436 = 0.6406926406926406
acuracy n = 437 = 0.6363636363636364
acuracy n = 438 = 0.6363636363636364
acuracy n = 439 = 0.6363636363636364
acuracy n = 440 = 0.6363636363636364
acuracy n = 441 = 0.6363636363636364
acuracy n = 442 = 0.6363636363636364
acuracy n = 443 = 0.6363636363636364
acuracy n = 444 = 0.6363636363636364
acuracy n = 445 = 0.6363636363636364
acuracy n = 446 = 0.6363636363636364
acuracy n = 447 = 0.6363636363636364
acuracy n = 448 = 0.6363636363636364
acuracy n = 449 = 0.6363636363636364
acuracy n = 450 = 0.6363636363636364
acuracy n = 451 = 0.6363636363636364
acuracy n = 452 = 0.6363636363636364
acuracy n = 453 = 0.6363636363636364
acuracy n = 454 = 0.6363636363636364
acuracy n = 455 = 0.6363636363636364
acuracy n = 456 = 0.6363636363636364
acuracy n = 457 = 0.6363636363636364
acuracy n = 458 = 0.6363636363636364
acuracy n = 459 = 0.6363636363636364
acuracy n = 460 = 0.6363636363636364
acuracy n = 461 = 0.6363636363636364
acuracy n = 462 = 0.6363636363636364
acuracy n = 463 = 0.6363636363636364
acuracy n = 464 = 0.6363636363636364
acuracy n = 465 = 0.6363636363636364
acuracy n = 466 = 0.6363636363636364
acuracy n = 467 = 0.6363636363636364
acuracy n = 468 = 0.6363636363636364
acuracy n = 469 = 0.6363636363636364
acuracy n = 470 = 0.6363636363636364
acuracy n = 471 = 0.6363636363636364
acuracy n = 472 = 0.6363636363636364
acuracy n = 473 = 0.6320346320346321
acuracy n = 474 = 0.6320346320346321
acuracy n = 475 = 0.6320346320346321
acuracy n = 476 = 0.6320346320346321
acuracy n = 477 = 0.6320346320346321
acuracy n = 478 = 0.6320346320346321
acuracy n = 479 = 0.6320346320346321
acuracy n = 480 = 0.6320346320346321
acuracy n = 481 = 0.6320346320346321
acuracy n = 482 = 0.6320346320346321
acuracy n = 483 = 0.6320346320346321
acuracy n = 484 = 0.6320346320346321
acuracy n = 485 = 0.6363636363636364
acuracy n = 486 = 0.6320346320346321
acuracy n = 487 = 0.6320346320346321
acuracy n = 488 = 0.6363636363636364
acuracy n = 489 = 0.6363636363636364
acuracy n = 490 = 0.6363636363636364
acuracy n = 491 = 0.6320346320346321
acuracy n = 492 = 0.6363636363636364
acuracy n = 493 = 0.6363636363636364
acuracy n = 494 = 0.6363636363636364
acuracy n = 495 = 0.6363636363636364
acuracy n = 496 = 0.6363636363636364
acuracy n = 497 = 0.6363636363636364
acuracy n = 498 = 0.6363636363636364
acuracy n = 499 = 0.6363636363636364
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="c1"># n = list(range(2,500))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">acuracy</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Tugas 7_48_0.png" src="_images/Tugas 7_48_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">max</span><span class="p">(</span><span class="n">acuracy</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.6666666666666666
</pre></div>
</div>
</div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="Tugas%206.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Tugas 6 - Decision Tree</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Tugas%208.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Tugas 8 - Regression Linier</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Saiyidati Vienna Arum Pratama<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>